{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0e75122-2c12-431a-bab4-e91bbc15f245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaders created successfully!\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define transformations for the training and test data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # Normalize the data to mean=0.1307 and std=0.3081\n",
    "])\n",
    "\n",
    "# Download and load the training and test datasets\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create DataLoader for training and test datasets\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "print(\"Data loaders created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab55ae62-1807-4a3d-8312-e0bf7a1831ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created successfully!\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # Convolutional layer 1: 1 input channel (grayscale), 32 output channels, 3x3 kernel size\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        # Convolutional layer 2: 32 input channels, 64 output channels, 3x3 kernel size\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        # Max-pooling layer: 2x2 window size\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # Fully connected layer 1: 64*7*7 input features, 128 output features\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        # Fully connected layer 2: 128 input features, 10 output features (for 10 classes)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        # Dropout layer to avoid overfitting\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))  # Apply ReLU activation, convolution, and pooling\n",
    "        x = self.pool(torch.relu(self.conv2(x)))  # Apply ReLU activation, convolution, and pooling\n",
    "        x = x.view(-1, 64 * 7 * 7)  # Flatten the feature maps\n",
    "        x = torch.relu(self.fc1(x))  # Apply ReLU activation to fully connected layer 1\n",
    "        x = self.dropout(x)  # Apply dropout\n",
    "        x = self.fc2(x)  # Output layer\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "model = CNN()\n",
    "\n",
    "print(\"Model created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adea84c2-9aa4-4eb7-99e5-442e2d474f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Epoch [1/5], Loss: 0.1682\n",
      "Epoch [2/5], Loss: 0.0567\n",
      "Epoch [3/5], Loss: 0.0411\n",
      "Epoch [4/5], Loss: 0.0317\n",
      "Epoch [5/5], Loss: 0.0244\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "# Check if a GPU is available, otherwise fallback to CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Move the model to the selected device (GPU or CPU)\n",
    "model.to(device)\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop with GPU support\n",
    "num_epochs = 5  # You can increase it later\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        # Move data (images and labels) to the selected device\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
    "\n",
    "print(\"Training completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02db9a87-4522-4980-bf36-6250cbbd3448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 10000 test images: 99.29%\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the model on the 10000 test images: {100 * correct / total:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de94233c-65eb-4aff-9b8e-212bc46c8d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), 'mnist_cnn.pth')\n",
    "print(\"Model saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b40d598-13c5-472a-90a3-f96c43d2dc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Initialize a new instance of the model and load the saved weights\n",
    "loaded_model = CNN()\n",
    "loaded_model.load_state_dict(torch.load('mnist_cnn.pth'))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "loaded_model.eval()\n",
    "print(\"Model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "652d142d-597f-475a-915f-01dc0026b136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Tkinter root window\n",
    "root = tk.Tk()\n",
    "root.title(\"MNIST Digit Drawer\")\n",
    "root.geometry(\"600x600\")\n",
    "\n",
    "# Canvas for drawing\n",
    "canvas = tk.Canvas(root, width=500, height=500, bg=\"white\")\n",
    "canvas.pack(pady=20)\n",
    "\n",
    "# Image for drawing, used for prediction\n",
    "img = Image.new(\"L\", (500, 500), 255)  # L mode for grayscale\n",
    "draw = ImageDraw.Draw(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d631a090-8794-4b58-97ec-4e6e7310ca13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2165307168128draw_on_canvas'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Draw method for the canvas\n",
    "def draw_on_canvas(event):\n",
    "    x1, y1 = (event.x - 5), (event.y - 5)\n",
    "    x2, y2 = (event.x + 5), (event.y + 5)\n",
    "    canvas.create_oval(x1, y1, x2, y2, fill=\"black\", width=10)\n",
    "    draw.line([x1, y1, x2, y2], fill=0, width=10)\n",
    "\n",
    "# Set up event bindings\n",
    "canvas.bind(\"<B1-Motion>\", draw_on_canvas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3409a246-0e5f-46ab-a223-16c8ba384cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clear the canvas\n",
    "def clear_canvas():\n",
    "    canvas.delete(\"all\")\n",
    "    draw.rectangle([0, 0, 500, 500], fill=255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e307ea6-19dd-4950-b502-c5e54168e7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict the digit\n",
    "def predict_digit():\n",
    "    # Convert canvas drawing to a format that the model understands\n",
    "    img_resized = img.resize((28, 28), Image.Resampling.LANCZOS)  # Resize to 28x28 for MNIST\n",
    "    img_tensor = transform(img_resized).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Get model prediction\n",
    "    with torch.no_grad():\n",
    "        output = model(img_tensor)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "    \n",
    "    # Display the prediction result\n",
    "    messagebox.showinfo(\"Prediction\", f\"Predicted digit: {predicted.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee9ae325-2beb-4940-8c1e-86dfe137ee85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create buttons for prediction and clearing the canvas\n",
    "predict_button = tk.Button(root, text=\"Predict\", command=predict_digit, width=20, height=2)\n",
    "predict_button.pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "clear_button = tk.Button(root, text=\"Clear\", command=clear_canvas, width=20, height=2)\n",
    "clear_button.pack(side=tk.RIGHT, padx=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08a5db0b-1bb3-4c47-b97f-a0345ca1e163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the application\n",
    "root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
