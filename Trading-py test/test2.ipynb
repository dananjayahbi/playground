{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix multiplication on GPU completed in 15.1931 seconds.\n",
      "Matrix multiplication on CPU completed in 2.7354 seconds.\n",
      "GPU result matches CPU result!\n"
     ]
    }
   ],
   "source": [
    "from numba import cuda\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "\n",
    "# CUDA kernel for matrix multiplication\n",
    "@cuda.jit\n",
    "def matrix_multiply(A, B, C):\n",
    "    row, col = cuda.grid(2)  # Get row and column index of C\n",
    "    if row < C.shape[0] and col < C.shape[1]:\n",
    "        temp = 0.0\n",
    "        for k in range(A.shape[1]):  # Perform dot product of A's row and B's column\n",
    "            temp += A[row, k] * B[k, col]\n",
    "        C[row, col] = temp\n",
    "\n",
    "# Increase matrix size to stress the GPU\n",
    "N = 8192  # Use a larger matrix size to increase GPU workload\n",
    "A = np.random.rand(N, N).astype(np.float32)\n",
    "B = np.random.rand(N, N).astype(np.float32)\n",
    "C = np.zeros((N, N), dtype=np.float32)\n",
    "\n",
    "# Transfer data to GPU\n",
    "A_gpu = cuda.to_device(A)\n",
    "B_gpu = cuda.to_device(B)\n",
    "C_gpu = cuda.device_array((N, N), dtype=np.float32)\n",
    "\n",
    "# Define grid and block size\n",
    "threads_per_block = (16, 16)  # 16x16 threads per block\n",
    "blocks_per_grid_x = math.ceil(A.shape[0] / threads_per_block[0])\n",
    "blocks_per_grid_y = math.ceil(B.shape[1] / threads_per_block[1])\n",
    "blocks_per_grid = (blocks_per_grid_x, blocks_per_grid_y)\n",
    "\n",
    "# Measure time for matrix multiplication on the GPU\n",
    "start = time.time()\n",
    "\n",
    "# Launch kernel\n",
    "matrix_multiply[blocks_per_grid, threads_per_block](A_gpu, B_gpu, C_gpu)\n",
    "\n",
    "# Synchronize to wait for GPU to finish processing before moving forward\n",
    "cuda.synchronize()\n",
    "\n",
    "# Copy result back to CPU\n",
    "C_result = C_gpu.copy_to_host()\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Matrix multiplication on GPU completed in {end - start:.4f} seconds.\")\n",
    "\n",
    "# Measure CPU-based matrix multiplication for comparison\n",
    "start_cpu = time.time()\n",
    "C_cpu = np.dot(A, B)\n",
    "end_cpu = time.time()\n",
    "\n",
    "print(f\"Matrix multiplication on CPU completed in {end_cpu - start_cpu:.4f} seconds.\")\n",
    "\n",
    "# Check if the GPU result matches the CPU result\n",
    "if np.allclose(C_result, C_cpu, atol=1e-3):  # Allow for small floating point tolerance\n",
    "    print(\"GPU result matches CPU result!\")\n",
    "else:\n",
    "    print(\"Mismatch between GPU and CPU results.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
